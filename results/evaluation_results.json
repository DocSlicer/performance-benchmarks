{
  "by_dataset": {
    "cuad": {
      "fixed_token": {
        "recall@1": 0.37406744255446134,
        "recall@3": 0.5902715607281408,
        "recall@5": 0.6988958519844822,
        "recall@10": 0.8470605789316622,
        "mrr@1": 0.37406744255446134,
        "mrr@3": 0.4687406744255446,
        "mrr@5": 0.4935616233960012,
        "mrr@10": 0.5135070436211887,
        "ndcg@1": 0.37406744255446134,
        "ndcg@3": 0.4359604619363679,
        "ndcg@5": 0.4838027642284268,
        "ndcg@10": 0.5479519242276701,
        "questions_evaluated": 6702,
        "questions_with_relevant": 6702,
        "total_chunks": 15083,
        "avg_chunk_tokens": 492
      },
      "recursive": {
        "recall@1": 0.3728737690241719,
        "recall@3": 0.5813190092509699,
        "recall@5": 0.6918830199940317,
        "recall@10": 0.8313936138466129,
        "mrr@1": 0.3728737690241719,
        "mrr@3": 0.4640157167014822,
        "mrr@5": 0.4892842932457973,
        "mrr@10": 0.5080190466716877,
        "ndcg@1": 0.3728737690241719,
        "ndcg@3": 0.4406046256679113,
        "ndcg@5": 0.48591166793262164,
        "ndcg@10": 0.5440938289278604,
        "questions_evaluated": 6702,
        "questions_with_relevant": 6702,
        "total_chunks": 18959,
        "avg_chunk_tokens": 361
      },
      "flat_header": {
        "recall@1": 0.6940688660537228,
        "recall@3": 0.8402740219938706,
        "recall@5": 0.9006670272219217,
        "recall@10": 0.9617811429601586,
        "mrr@1": 0.6940688660537228,
        "mrr@3": 0.7585181179015684,
        "mrr@5": 0.7725887867315666,
        "mrr@10": 0.7809427947610749,
        "ndcg@1": 0.6940688660537228,
        "ndcg@3": 0.75584502179246,
        "ndcg@5": 0.7835396826908096,
        "ndcg@10": 0.8110877388026223,
        "questions_evaluated": 5547,
        "questions_with_relevant": 5547,
        "total_chunks": 5517,
        "avg_chunk_tokens": 1027
      },
      "docling": {
        "recall@1": 0.3484620024125452,
        "recall@3": 0.5459891435464415,
        "recall@5": 0.6477683956574186,
        "recall@10": 0.7724668275030157,
        "mrr@1": 0.3484620024125452,
        "mrr@3": 0.43425814234016885,
        "mrr@5": 0.4576372135102533,
        "mrr@10": 0.47424039529362205,
        "ndcg@1": 0.3484620024125452,
        "ndcg@3": 0.41307845667902776,
        "ndcg@5": 0.4506287264690654,
        "ndcg@10": 0.4958582052317591,
        "questions_evaluated": 6632,
        "questions_with_relevant": 6632,
        "total_chunks": 68463,
        "avg_chunk_tokens": 95
      },
      "docslicer": {
        "recall@1": 0.6122583479789103,
        "recall@3": 0.7675746924428822,
        "recall@5": 0.8216168717047452,
        "recall@10": 0.8916959578207382,
        "mrr@1": 0.6122583479789103,
        "mrr@3": 0.6817882249560633,
        "mrr@5": 0.6941673989455185,
        "mrr@10": 0.7035600956844366,
        "ndcg@1": 0.6122583479789103,
        "ndcg@3": 0.6580832909470739,
        "ndcg@5": 0.6785537627249174,
        "ndcg@10": 0.708229859281788,
        "questions_evaluated": 4552,
        "questions_with_relevant": 4552,
        "total_chunks": 19450,
        "avg_chunk_tokens": 328
      }
    },
    "acl": {
      "fixed_token": {
        "recall@1": 0.36363636363636365,
        "recall@3": 0.5643939393939394,
        "recall@5": 0.6742424242424242,
        "recall@10": 0.8371212121212122,
        "mrr@1": 0.36363636363636365,
        "mrr@3": 0.4494949494949495,
        "mrr@5": 0.4750631313131313,
        "mrr@10": 0.4973274410774411,
        "ndcg@1": 0.36363636363636365,
        "ndcg@3": 0.46175515660996863,
        "ndcg@5": 0.5048725552037607,
        "ndcg@10": 0.5634782801528117,
        "questions_evaluated": 264,
        "questions_with_relevant": 264,
        "total_chunks": 961,
        "avg_chunk_tokens": 491
      },
      "recursive": {
        "recall@1": 0.3106060606060606,
        "recall@3": 0.5340909090909091,
        "recall@5": 0.6704545454545454,
        "recall@10": 0.8181818181818182,
        "mrr@1": 0.3106060606060606,
        "mrr@3": 0.4078282828282829,
        "mrr@5": 0.4388888888888889,
        "mrr@10": 0.4595283189033189,
        "ndcg@1": 0.3106060606060606,
        "ndcg@3": 0.4196212541005573,
        "ndcg@5": 0.4729063525133897,
        "ndcg@10": 0.529722553729615,
        "questions_evaluated": 264,
        "questions_with_relevant": 264,
        "total_chunks": 1146,
        "avg_chunk_tokens": 399
      },
      "flat_header": {
        "recall@1": 0.3403361344537815,
        "recall@3": 0.6428571428571429,
        "recall@5": 0.7647058823529411,
        "recall@10": 0.9327731092436975,
        "mrr@1": 0.3403361344537815,
        "mrr@3": 0.4726890756302521,
        "mrr@5": 0.5004201680672269,
        "mrr@10": 0.5232959850606909,
        "ndcg@1": 0.3403361344537815,
        "ndcg@3": 0.5081063051610085,
        "ndcg@5": 0.5581576874797982,
        "ndcg@10": 0.61507773795396,
        "questions_evaluated": 238,
        "questions_with_relevant": 238,
        "total_chunks": 1010,
        "avg_chunk_tokens": 413
      },
      "docling": {
        "recall@1": 0.3712121212121212,
        "recall@3": 0.7045454545454546,
        "recall@5": 0.8522727272727273,
        "recall@10": 0.9924242424242424,
        "mrr@1": 0.3712121212121212,
        "mrr@3": 0.5189393939393939,
        "mrr@5": 0.553030303030303,
        "mrr@10": 0.5726400913900914,
        "ndcg@1": 0.3712121212121212,
        "ndcg@3": 0.5597372108032088,
        "ndcg@5": 0.6211681464779581,
        "ndcg@10": 0.6720894883446109,
        "questions_evaluated": 264,
        "questions_with_relevant": 264,
        "total_chunks": 432,
        "avg_chunk_tokens": 981
      },
      "docslicer": {
        "recall@1": 0.5130434782608696,
        "recall@3": 0.8173913043478261,
        "recall@5": 0.8521739130434782,
        "recall@10": 0.9391304347826087,
        "mrr@1": 0.5130434782608696,
        "mrr@3": 0.6463768115942029,
        "mrr@5": 0.6546376811594202,
        "mrr@10": 0.6675086266390614,
        "ndcg@1": 0.5130434782608696,
        "ndcg@3": 0.6414311604041284,
        "ndcg@5": 0.6550598204233056,
        "ndcg@10": 0.6924399579409914,
        "questions_evaluated": 115,
        "questions_with_relevant": 115,
        "total_chunks": 1089,
        "avg_chunk_tokens": 413
      }
    },
    "rfc": {
      "fixed_token": {
        "recall@1": 0.288785046728972,
        "recall@3": 0.5214953271028038,
        "recall@5": 0.6457943925233645,
        "recall@10": 0.7897196261682243,
        "mrr@1": 0.288785046728972,
        "mrr@3": 0.3901869158878505,
        "mrr@5": 0.41915887850467287,
        "mrr@10": 0.43859145527369825,
        "ndcg@1": 0.288785046728972,
        "ndcg@3": 0.40132320179564146,
        "ndcg@5": 0.4569105809131358,
        "ndcg@10": 0.5098947454404984,
        "questions_evaluated": 1070,
        "questions_with_relevant": 1070,
        "total_chunks": 6292,
        "avg_chunk_tokens": 494
      },
      "recursive": {
        "recall@1": 0.2588785046728972,
        "recall@3": 0.49065420560747663,
        "recall@5": 0.6308411214953271,
        "recall@10": 0.7644859813084112,
        "mrr@1": 0.2588785046728972,
        "mrr@3": 0.35841121495327105,
        "mrr@5": 0.39065420560747666,
        "mrr@10": 0.4089782673193888,
        "ndcg@1": 0.2588785046728972,
        "ndcg@3": 0.37619152318707755,
        "ndcg@5": 0.43556223859461146,
        "ndcg@10": 0.4841447826782271,
        "questions_evaluated": 1070,
        "questions_with_relevant": 1070,
        "total_chunks": 6687,
        "avg_chunk_tokens": 434
      },
      "flat_header": {
        "recall@1": 0.3886363636363636,
        "recall@3": 0.6977272727272728,
        "recall@5": 0.8647727272727272,
        "recall@10": 0.9840909090909091,
        "mrr@1": 0.3886363636363636,
        "mrr@3": 0.5234848484848486,
        "mrr@5": 0.5613257575757575,
        "mrr@10": 0.578051948051948,
        "ndcg@1": 0.3886363636363636,
        "ndcg@3": 0.560378740415691,
        "ndcg@5": 0.6321836830548799,
        "ndcg@10": 0.6741113544633129,
        "questions_evaluated": 880,
        "questions_with_relevant": 880,
        "total_chunks": 1443,
        "avg_chunk_tokens": 1810
      },
      "docling": {
        "recall@1": 0.12018779342723004,
        "recall@3": 0.20093896713615023,
        "recall@5": 0.25821596244131456,
        "recall@10": 0.3586854460093897,
        "mrr@1": 0.12018779342723004,
        "mrr@3": 0.15477308294209705,
        "mrr@5": 0.16773082942097026,
        "mrr@10": 0.18077129443326626,
        "ndcg@1": 0.12018779342723004,
        "ndcg@3": 0.1387653523294727,
        "ndcg@5": 0.16074851217213848,
        "ndcg@10": 0.1917535639415597,
        "questions_evaluated": 1065,
        "questions_with_relevant": 1065,
        "total_chunks": 50874,
        "avg_chunk_tokens": 53
      },
      "docslicer": {
        "recall@1": 0.6175,
        "recall@3": 0.8425,
        "recall@5": 0.90875,
        "recall@10": 0.97,
        "mrr@1": 0.6175,
        "mrr@3": 0.7197916666666667,
        "mrr@5": 0.7349166666666666,
        "mrr@10": 0.7432013888888889,
        "ndcg@1": 0.6175,
        "ndcg@3": 0.7288632420409732,
        "ndcg@5": 0.7571955016449384,
        "ndcg@10": 0.7820070656441591,
        "questions_evaluated": 800,
        "questions_with_relevant": 800,
        "total_chunks": 6245,
        "avg_chunk_tokens": 381
      }
    }
  },
  "aggregated": {
    "fixed_token": {
      "recall@1": 0.3421629509732657,
      "recall@5": 0.6729775562500903,
      "mrr@5": 0.4625945444046018,
      "ndcg@5": 0.48186196678177445,
      "total_chunks": 22336,
      "avg_tokens": 492
    },
    "recursive": {
      "recall@1": 0.31411944476770987,
      "recall@5": 0.6643928956479681,
      "mrr@5": 0.4396091292473876,
      "ndcg@5": 0.46479341968020754,
      "total_chunks": 26792,
      "avg_tokens": 398
    },
    "flat_header": {
      "recall@1": 0.4743471213812893,
      "recall@5": 0.8433818789491966,
      "mrr@5": 0.6114449041248503,
      "ndcg@5": 0.6579603510751626,
      "total_chunks": 7970,
      "avg_tokens": 1083
    },
    "docling": {
      "recall@1": 0.2799539723506322,
      "recall@5": 0.5860856951238201,
      "mrr@5": 0.3927994486538422,
      "ndcg@5": 0.4108484617063873,
      "total_chunks": 119769,
      "avg_tokens": 376
    },
    "docslicer": {
      "recall@1": 0.5809339420799267,
      "recall@5": 0.8608469282494079,
      "mrr@5": 0.694573915590535,
      "ndcg@5": 0.6969363615977205,
      "total_chunks": 26784,
      "avg_tokens": 374
    }
  },
  "methods": [
    "fixed_token",
    "recursive",
    "flat_header",
    "docling",
    "docslicer"
  ],
  "k_values": [
    1,
    3,
    5,
    10
  ]
}